Application_ID,Ideas
1,A global network of hydrophones with built in low powered AI audio classifiers could be used to monitor the global movements of marine organisms. It would also be able to triangulate identify areas of high noise pollution.  
2,Audio Language Models for Bioacoustics Recognition
3,"Audio recognition of individuals. As species recognition from audio improves rapidly (e.g. for birds, bats), can we think about distinguishing individuals within a species from their calls? Noting that (a) voice recognition in humans is well-understood (from 'voiceprint' vectors), and (b) many species are observed to recognise individuals from their calls (therefore the signal processing is possible). A potential application of such a capability might be counting of individuals within a local population (e.g. at small scale for use in forest canopy, or even at larger scale e.g. night-time migration, combined with supervised learning and probabilistic counting methods)."
4,"Distributed Acoustic Sensing (DAS) can sense sound in real time along the dense network of fibre-optic telecommunication cables that cover both deep ocean and coastal areas around the globe. It can enable audio recognition of cetaceans, seals and human activities (vessel traffic, deep-sea mining etc.) even in the most remote oceanic areas. Seamounts rising to a few hundred meters below the sea surface are known to promote biological productivity of the ocean. Audio recognition of vocal species using optical fiber cables and DAS may be the only realistic way of monitoring these remote oceanic oases of productivity. The network of optical fiber cables for telecommunication makes it possible to upscale the distribution of audio recorders.  "
5,"There is a potential for substantial improvements in global distribution data and monitoring change through the large scale operation of auditory monitoring, perhaps with solar power for long term use. The challenge is to find means of creating the network. Options include working with other organisations with a global network or establising before developments take place to monitor consequences. "
6,"Currently those citizen scientists who contribute data just receive acknowledgement. An option is for bespoke feedback identifying the most interesting aspect of the submitted data. The aim is the encopurage further use, minimise errors by identifying unusual features and increase the knowledge of the users. "
7,"Learning where we need more data: citizen science data especially is very biased spatially at the moment, but can we generate maps that predict where we should focus data gathering efforts to maximise the probability of interesting new observations "
8,"Discovering species in data. Current AI methods for classifying what species are present in an image or an audio recording typically require a pre-defined set of species that may be present to be known in advance. There is potential for recently introduced ""category discovery"" methods to be applied here. These methods aim to discover novel concepts in data (e.g. a previously undescribed species). "
9,Detecting and enforcing wildlife crime is increasingly based on intelligence gathering activities that could benefit from AI.  AI would enable better scouring of electronic resources (like  the internet) to identify individuals buying/selling CITES listed organisms and do so rapidly so that enforcement activity can be effective.  AI can also be harnessed to scan satellite imagery looking for real-time poaching activities to aid in directing enforcement teams.
10,"Monitor online wildlife trade. Computer vision (i.e., automatic processing and understanding of images) and natural language processing (i.e., automatic processing of textual content), as well as multimodal machine learning (i.e., automatic processing of multiple sources of information, such as text, images, and audio) can be used to understand where, when, how, why, and what species and wildlife products are being traded on which online platforms.    "
11,"Taking the temperature of society on conservation-relevant issues: Social media is a treasure trove of data reflecting what people are talking about, what their concerns are with a high temporal resolution. It is often possible to extract data on location at quite fine spatial resolution and it can be possible to extract other covariates. This enormous source of data is already being mined using AI, for example carrying out sentiment analysis surrounding an issue following an event. However it seems likely to have as yet unmined potential for conservation. For example, anticipating changes in demand for certain illegally traded species, evaluating the impact of awareness-raising or fund-raising campaigns…. "
12,"AI for monitoring the movement of invasive species and illegally traded species across the global trade network, given the lack of human resources for inspecting containers. Data on when invasives or illegally trafficked wildlife are found at ports of entry could be linked to exporting country, time of year, type of shipment (flowers/timber/cars etc,), exporting company, type of container among other metadata to try and identify which future containers should be highlighted for closer inspection."
13,Dealing with data sparsity using methods from recommender systems. A key challenge in species / ecosystem monitoring is data sparsity. But there is some commonality here with recommender systems used by Internet companies to predict user preferences. Such recommender systems achieve a high level of success by combining data across all users and exploiting hidden correlations (e.g. using collaborative filtering). Can similar approaches benefit species / ecosystem monitoring?
14,"To improve ecosystem services assessment (i.e. extent, flow/provision, valuing) by integrating field, remote sensing and market data. "
15,To improve the traceability of supply chain models
16,"Track the changes in ecosystem health. Identify key indicators for different ecosystems and can utilize high temporal-spatial remote sensing and other data to identify the changes in ecosystem health, or increasing pressures (climatic factors, visitation, fires, market needs) and send out early warnings for better intervention. "
17,"Using AI to better understand species' distributions. Currently, our understanding of species' distributions is based on extremely patchy sampling and incomplete knowledge of species' ecology. AI could improve models of species' distributions by integrating data on specimen locations, citizen science observations, images on social media, environmental and ecological data, remote sensing data and other spatial datasets on human impacts."
18,"Using AI to detect emerging threats to species (e.g. through online wildlife trade, spread of invasive alien species, documentation on social media of novel impacts) and sites of biodiversity importance (e.g. through detecting habitat loss (particularly beyond forests and fires, where this is already happening effectively), human encroachment (e.g. through the spread of roads, dwellings), infrastructure (powerlines, fences, coastal development) etc, and relating these to the sensitivity of the biodiversity features for which the site is important). 
"
19,"
Human-animal conflicts which contribute to negative and drastic decision-making based on social fears have been one of the major obstacles for wildlife conservation, especially around mammals. Mammals are often registered as protected species or “natural monuments”, however, even these highest social protections could be removed when the incidents of the conflicts are reported repeatedly in the media.

The number of incidents of human-animal conflicts has increased dramatically over the past years (WWF 2021). This is due to the climate and landuse change causing drastic impacts on their habitats and food provisions. For example, there were 8,839 wild bear sighting in residential areas in Japan between April and October 2023, with 5 death and 180 injuries. This is said to be due to the nation wide acorn crop failure due to the unusally hot summer. Warm winter means that wild bears also did not hibernated long enough to rest. The increase of abondoned agricultural lands due to the population declines, and unharvested fruit trees in villages exasibated the situation.  

AI cameras are already in use in different countries to track mammals, and warn communities when they are in vicinity. In the future, combinations of data on environmental and anthropogenic drivers will happen including: climate predictions, food growth predictions, alternative food existence, patterns of animal migrations, locations of past human-animal conflicts, land use change, existence of buffer zones, existence of registered hunters, abandoned farmlands, sighting of animals by citizens. 

AI with combined short and long term data sets will provide not only more accurate predictions with less panic in society, as well as opportunities to take measures as early as possible, including planting different types of trees with nuts to become alternative wild food for animals. 

Reference: 
Dertien, J. S., Negi, H. et al. (2023) Mitigating human-wildlife conflict and monitoring endangered tigers using a real-time camera-based alert system, BioScience, 73(10): 1-10.
World Economic Forum (2024) AI in conservation: Where we came from – and where we are heading. 
WWF (2021) A future for all: The need for human-wildlife coexistence. WWF"
20,"Establishing causality of interventions using multimodal data: can we use lots of different modality of sensing (e.g. camera, acoustics, plotting) to identify ecological invariants that hold true across all of the different views. This in turn will help validate causation of interventions"
21,"Adaptive management of protected areas and dynamic monitoring. While many protected areas have been established, but most of them lack the capacity to turn data into information to facilitate better management. AI can help to automatically generate monitoring reports, and identify data gaps and notable trends that are worth further investigation. It ideally can identify a new monitoring framework for the next management cycle (including sampling methods, monitoring locations and ) addressing the data needs for the evaluation of new interventions and threats."
22,"Preventing poaching in protected areas.  AI technology is already being used to help catch poachers and combat wildlife poaching.  Examples include predictive analytics (e.g. Protection Assistant for Wildlife Security) that use machine learning on historical poaching data to predict areas of high risk and optimise patrol routes for ranger;  anti-poaching cameras to detect humans in motion-triggered images and send alerts to park authorities;  and facial recognition to distinguish known rangers from unknown individuals who could be potential poachers.  AI may improve effectiveness,  but major ethical issues need to be urgently addressed, such as the ethics of excluding local people from ancestral lands using fortress conservation approaches, and the risks of alienating local people from wildlife conservation."
23,"Federated AI learning: given multiple ""data islands"" which cannot be shared (e.g. species observations across IBAT partners and hunting data from TRAFFIC), can we train a distributed model which is a representation of the underlying raw data but still be representative and useful? this would allow the unification of the world's biodiversity databases into models which can be shared without leaking the raw data."
24,"Dataset subselection methods to enable efficient fine-tuning for specific conservation use cases from large public datasets, including useful remapping of similar categories and/or automated category granularity selection for optimal robustness."
25,"Open-ended text-based query from multimodal conservation data, moving towards more interactive AI systems without needing large supervised training sets to build models that can find relevant data for each possible scientific question. It will also open up access to secondary data in ecological data collections (backgrounds of images, species interactions, behaviors, etc)"
26,"An individual's environmental cumulative annual footprint could be calculated from online purchases such as travel, food and other items."
27,"Better field to fork maps: our supply chain data for food is currently port to port, but there is a long path from field to port.  we could use reinforcement learning to map out likely routes that production from every pasture/field will take to get to a port for exports, and thus map out danger areas (""ghost roads"") where it impinges on nature"
28,"Exploration of financial markets to determine investment portfolios most likely to result in net nature-positive outcomes, and that provide a specified risk and return for the investor."
29,"The combining of data on changes combined with citizen science data and automated data means can produce bespoke accounts of diversity either regularly or on demand according to the specific interests of the reader. For example, some may be interested in global environmental changes with another concerned about local wildlife and what has been seen recently. "
30,AI supporting the translation of data to actionable insights in real time on multi modal data platforms This is happening to some degree already but this is yet to happen at scale in real-time.
31,"Automated biodiversity monitoring networks emerge to close the biodiversity data gaps; streams from multi-mode sources like imaging (camera traps, satellite), eDNA, and bioacoustics, are streamlined into harmonized and meaningful metrics that are actionable at national and the global scale."
32,"Better and closer to real-time detection of hyper-specific threats to biodiversity and changing ecosystem condition through geospatial AI/ML tools that summarise earth observation data/trends. Along with socio-economic data and supply chain information, this could lead to higher and more immediate accountability for those causing harm, and could lead to something of a reckoning."
33,"Better understanding the location of people in a landscape: Understanding where people are in a landscape is really important for a number of reasons: 1) as covariates in many analyses (for example human population density may be an important confounder in conservation impact evaluations) 2) to better how many people might be affected by a conservation intervention. While global datasets of human populations are rapidly increasing in quality (e.g. Open Building dataset and World Settlement Footprint), they might not work well in certain areas (e.g. people living in tropical forest) and older data is not available. AI could be very helpful for classifying arial photographs or satellite images to come up with better understanding of the distribution of people in a landscape."
34,Early warning of changes in landuse practices with significant implications for threatened species or ecosystems.
35,"Illegal wildlife trade detection. Automatic detection of the information (pictures, text, changing names) from trade, potential search, and chats to track illegal wildlife trade.  "
36,"Monitor the presence and abundance of species and ecosystems. Computer vision, natural language processing, and multimodal machine learning can be used to identify and count species and individuals, habitats, and ecosystems from camera trap images, remotely sensed data, drone images, social media content, audio recordings, etc. "
37,"Species, population and traits monitoring. Through AI, species/individual identification through images and sounds can be automated with the accumulation of training data and a better data-sharing mechanism. Further,  some traits can be tracked and monitored to facilitate conservation, such as prawn morphometrics for weight estimate. "
38,"Though I cannot see all national governments working together on a global environmental monitoring network that involves integration of a diversity of environmental data from satellites, drones, field stations, etc., and make these data available to all, I can imagine the bottom-up growth of such efforts and their integration facilitated by AI. Something similar to the Adapting Mosaic scenario of the Millennium Ecosystem Assessment. Most of the AI applications to conservation that I visualize involve some sort of central integration of tools and facilities, but there is also the option to look at the problem in a bottom-up way, by imagining an adaptable toolkit driven by AI that would give independence and autonomy to local governments or other local institutions, to collect data using flexible protocols, able to support planning and policy, generating outputs that are interoperable and comparable. Each would have sovereignty over their processes, but would be able to contribute to a global effort with help on AI."
39,How do we get AI to provide reliable species lists from large metagenomic datasets from e.g. eDNA surveys
40,"Conservation awareness. Embed conservation information and awareness-raising messages smartly into the interaction that the public may have on social media, generative AI and other platforms to lead the change in public perception and actions. Also, the conversations with AI may identify potential poachers, traders or people with the potential to support or devote themselves to conservation. Thus, identify tailored messages to lead positive change. "
41,"LLM conservation advisors. Fine tuning and retrieval augmented generation (RAG) of large language models based on trusted data sources (conservation evidence databases, curated literature, etc.) and relevant quantitative data (e.g. geography, species, agricultural or socioeconomic) to provide more trustworthy and useful information for practitioners. This type of approach is likely to be generalizable and will appear first in more quotidian commercial applications."
42,"The creation of lectures, labs and practical exercises and the development of curricula for teaching conservation science."
43,One or few shot classification accessible to end users. A platform where as a conservationist I could just upload my data and get pretty good classifications on everything.
44,"
Using AI to recognise species is already a reality,  with huge potential.  Deep neural networks are proving highly effective in recognizing species from various data sources including camera traps, mobile phone images, acoustic data, and even images of herbarium specimens.  Accuracy of recognition, and the inclusion of less-easy-to-identify groups will improve as more datasets labelled by experts are incorporated CNNs are combine with other neural network architectures to fuse information from multiple data modalities.  Challenges remain in obtaining sufficient training data, dealing with class imbalances, and interpreting the learned models to map distribution and abundances. 
"
45,"""Individual"" based monitoring takes off at a much wider scale. For instance, mapping and identifying individual trees automatically for a whole ecosystem/management area. Or the individual identification of animals to assess population trends/sizes. This allows for responsive monitoring and more tailored interventions (for instance, legal and trade responses in a specific region where one species of tree is disappearing)."
46,"Abundance estimation from semi-identifiable populations - make use of eg conformal prediction to accurately identify individuals to within sets of the population with uncertainty estimates, and adapt statistical population estimates to make use of these identified sets as opposed to identified individuals. This will enable us to make better use of lower-quality images (like camera trap images) for automated re-identification/abundance estimation."
47,"AI is used to identify species from images for seabed biodiversity surveys, but it is currently poor in several ways.  How do we get it to pick out when there are new species not previously known to science?"
48,"AI to detect new species
Existing AI systems are trained to identify specific species from images collected by sensors such as camera traps. But AI workflows have recently been developed for the detection and confirmation of unknown species status, providing a new solution, for example, for the acceleration of the documentation of ‘dark diversity’. The workflow can be coupled with a motion-activated, solar-powered machine equipped with a camera and a small computer, providing opportunities to collect information in biodiversity hotspots for months at a time. The approach could also be a game changer in terms of tracking how biodiversity is reshuffling with climate change. 

References
https://www.researchsquare.com/article/rs-3832815/v1 
https://globalnews.ca/news/10147726/montreal-research-artificial-intelligence-new-species/
"
49,"Generating historical datasets from arial photographs: A major challenge for causal inference from observational data (teasing out whether x caused y or is simply associated with it-vital for robust evaluation of the impact of conservation interventions) is historical data. Data on both outcomes of interest (species abundance, habitat condition, habitat extent), or confounders (variables affecting both whether a site gets a conservation intervention or not and the outcome) are really valuable. Arial photographs will often have a longer time series than satellites and may be better resolution (certainly than earlier satellites). Some species (or their signs) could be counted directly using AI (I am sure this is being done for elephants, ungulates etc) but also extracting data on trends in grazing animals, presence of specific crops, presence of people in a landscape, could be extremely valuable.
(NB I am aware part of this fits under images of biodiversity and part under remote sensing)
"
50,"In seabed biodiversity surveys how do we get AI to identify species with very large morphological variation, like some sponges? Or organisms that look very different from different angles"
51,"Novel category discovery in fine-grained and imbalanced data - this has already started to be explored but I think it's a very exciting direction, particularly for datasets with many unknown species (moth camera traps, deep sea video)"
52,The use of Wifi routers to 3D model spaces in real time in replacement of camera traps. AI is the only way to process the high resolution information to distinguish the differences in wavelengths and construct the image 
53,To improve efficiency in the analysis of camera trap images
54,"Training AI image classifiers, likely on hyperspectral remote sensing data, to be able to recognise a suite of tree syndromes which indicate the presence of disease or pests from high resolution satellite imagery. Smaller models and procedures have been produced for individual diseases (red needle cast, ash dieback) however I do not believe this has been scaled up in a generalised way. "
55,Use computer vision models fine tuned to identify plants to recognise species from google street view images. This dataset of positively identified roadside plants could be paired with LIDAR and satellite data covering the same location to provide ground truthing. These ground-truthed satellite models could potentially then be used to recognise similar species from satellite imagery. 
56,"Using AI-enabled camera systems for assessing fisheries bycatch compliance.
Commercial fisheries cause bycatch of seabird species that is driving some species of albatrosses and large petrels towards extinction. A range of highly effective mitigation measures have been developed, and Regional Fisheries Management Organisations require implementation of such measures. However, detecting compliance relies on boat-based observers, which is resource intensive. AI-enabled on-board camera systems could record seabird presence, interactions with fishing gear (e.g. cable strikes), bycatch (i.e. ensnared birds) and use of mitigation measures (compliance), enabling safer, cheaper and more reliable monitoring of compliance.
"
57,Using computer vision models fine-tuned on invasive species (using open resources such as iNaturalist) to recognise invasive species from google street view images (likely focusing on plants). This could also include the ’pathology’ of other invasive species (such as plants being eaten by insects). This could provide insights into current and historic species distribution of invasives. Highlight areas which require urgent management; act as an early warning system for highlighting where invasives may soon arrive; provide before/after imagery to assess the success of invasive species management. 
58,Very high fidelity image generation to increase training data for rare species in novel contexts or to generate data of species in appropriate contexts as their ranges change. This could enable much more robust endangered species monitoring and/or (stretch goal) re-identification models.
59,Vision Language Models for Animal Recognition and AI assistance 
60,"When surveying biodiversity from images of e.g. seabed assemblages humans are good at ignoring particles suspended in the water, but how do we improve AI in terms of ignoring irrelevant parts of the image but still giving good returns on the objects of interest?"
61,"AI to boost utility of Digital Twins
The concept of the digital twin (DT) has won giant attention in current years, having becoming part of the political sustainability agenda (e.g., in the ‘Destination Earth’ programme of the European Commission), with the vision of developing DTs for the climate, the ocean, and biodiversity. AI is likely to significantly improve the usefulness of DTs by enabling the running of simulations to explore specific scenarios and identify best options, supporting decision-making. 

References
https://www.cell.com/trends/ecology-evolution/fulltext/S0169-5347(23)00090-3 
https://link.springer.com/chapter/10.1007/978-3-031-58523-4_2 

"
62,"Building a terrestrial equivalent of weather forecasting: we could build diffusion models of land use, and use it to _predict_ the impact of a given landuse change (e.g. if we draw a road on a map, can the map adjust to predict ecosystem changes like forests retreating)"
63,"Digital twins for ecosystems. This suggestion addresses the general problem of predicting outcomes (and long-term success or not) of conservation interventions. While AI methods such as reinforcement learning are being explored there is currently a lack of rigour in their use in biology. A 'digital twin' is a system model which is coupled to, and learns from, actual data generated by the physical system. Digital twins are well understood and used in engineering, and are also starting to be used in earth sciences (e.g. oceanography). The proposal here is to explore and establish digital twins as a tool for ecosystem modelling and prediction. A key opportunity would be the peering of digital twins across multiple domains of expertise (e.g. ocean physics, fish populations, seabird ecology). Digital twins could provide a trusted platform for more rigorous development of AI methods for intervention modelling."
64,"Global ecosystem models simulate the dynamics of life on Earth, including the interactions between plants, animals, and the environment.  These models are valuable for modelling the impacts of climate change on nature in a human-dominated world (and visa versa).  However they have a serious believability problem:  predictions of Dynamic Global Vegetation Models do not align well with field measurements (e.g. of fluxes of greenhouse gas);  they fail to make reliable predictions of large-scales fires and drought-induced mortality even though large-scale disturbance events have profound effects on ecosystem functioning and biodiversity;  and they rarely include plant-animal interactions (the Madingley model being an exception!).    Many processes in the DGVMs are represented by semi-empirical semi-theoretical equations with parameters that need to be calibrated against observations. AI optimisation techniques could automate this calibration process, finding optimal parameter values that best fit the data across multiple scales.  Physics-inspired AI is another avenue worth pursuing. AI techniques such as reduced-order modelling could potentially find low-dimensional representations that capture the essential dynamics while being much faster to compute."
65,"To improve ecosystem models (i.e. classification, extent and state) based on remote sensing techniques. "
66,"Benchmarking of methods. The great progress in AI over the last 10 years can be attributed to algorithms (i.e. neural networks), hardware (i.e. GPUs), and datasets. The last point, i.e. the availability of large-scale datasets that can be used to benchmark and evaluate model performance should not be overlooked. While this point is not a direct advancement as a result of AI, it instead related to best practices from the AI community that can be applied to conservation research.  "
67,"Predict deforestation.  Deep learning can analyse large amounts of satellite imagery and other geospatial data to detect early signs and patterns of deforestation.  This allows the models to predict areas at high risk of future deforestation with high accuracy.  These predictions underpin ex ante estimates of the effectiveness of REDD+ projects and enable planning of conservation actions, particularly in tropical regions undergoing rapid deforestation "
68,"To predict hotspots of new agricultural expansion frontiers, so proactive monitoring and protection can be implemented"
69,"Using 'Nowcasting' for the real-time prediction of evolving threats where policy-makers or practitioners currently rely on patchy data or data that is released with significant lag times, such as illegal or unsustainable wildlife trade patterns."
70,"Large scale Earth Observation Foundational Models (EOFM) (e.g. Prithvi, Clay, SatMAE, ScaleMAE) open new possibilities for experimenting and training models to assess conservation outcomes directly from satellite imagery. Without EOFM, multi-sensor temporal deep learning approaches are possible, but may be cost-prohibitive to train and run at scale (e.g. agricultural yield monitoring). The next generation of EOFM are likely to be 1-2 orders of magnitude larger than current models."
71,"To predict the effectiveness (i.e. adoption, implementation and expected outcomes) of sustainability initiatives by targeted actors/users, avoiding to wait decades to confirm whether it actually worked"
72,"To reduce the design and implementation costs of ecosystem-based management practices, by predicting the biophysical variables and their required threshold values to meet desired outcomes. 
"
73,"Using AI to prioritise restoration efforts. We know we need to recover degraded habitats in order to avert extinctions and minimise climate change. AI could help us direct such efforts more efficiently, given habitat loss and degradation to date, and projected climate change, shifts in energy production, food production, human population distributions etc."
74,"Using AI to optimise spatial land-use plans that are biodiversity-inclusive. Given the need to feed the world and supply people with energy from renewable sources, and given projected climate change, where should we set aside land (and seas) for nature protection (to minimise the risk of extinctions, and maximise the provision of ecosystem services), and where should we use land and seas for producing food and energy, along with other human uses."
75,"Predicting rare plant locations: there are 150k data deficient plant species with <5 observations worldwide, but we don't really have a strategy for finding them as they are often masked by more common plants (and remote sensing is no use). can AI help us predict (perhaps through phylogeny or other theoretical relations) where we should get more observations?"
76,"Species distribution models:  SDMs can be important for conservation decision makers, e.g. assessing the impacts of land use change on biodiversity.  Based on species occurrence records or presence/absence records,  SDMs produce maps of the (relative) probability of occurrences using large datasets obtained from remote sensing and other sources. AI methods like machine learning are well-suited to integrate and process these heterogeneous datasets efficiently, handling missing data, noise, and non-linear relationships between predictors and species occurrence probability; they can automatically learn relevant features directly from raw spatial data and uncover complex patterns and interactions.  However, we are currently limited by the small amount of labelled data available to train models (especially in the case of plant species and non-vertebrate animals!), spatial biases in data collection,  temporal mismatches between field datasets and remote sensing layers  and challenges with assessing accuracy and avoiding overfitting. How can new AI approaches (e.g. physics-inspired AI and xAI) + new citizen science datasets address these problems?"
77,"Species range maps and derived products from have had limited use and distribution outside of the academic sphere due to protective licensing through IBAT. We should expect to see new open ML derived species range maps built based on iNaturalist and GBIF data. Recent proof-of-concept studies have shown significant promise to overcome biases inherent in such datasets, though will always differ from expert derived ranges. The ideal case would be to combine approaches to augment expert judgement with data-driven (AI) approaches to range mapping."
78,"To improve species distribution models, by improving the accuracy of their occurrence and absence under multiple environmental conditions; including threats"
79,"As a general rule, the performance of machine learning models improve with increasing quantities of data. This poses an issue for problems we want to solve that feature rare entities or infrequent occurrences and the lack of sufficient data in these domains limits the quality of resulting models. The rapidly maturing process of synthetic data generation could remedy this.

Model-based synthetic data generation leverages either large state-of-the-art language and vision models to produce new training examples, potentially leveraging the small existing collection. For example, a small number of photos of a rare species could be used to generate a virtually unlimited number of new images of the species in different environments and orientations. 

Simulation-based synthetic data generation uses modern photorealistic engines such as Unreal Engine and Unity to create training examples in potentially many different modalities such as mono or stereo RGB images, laser scans, 3D depth maps and videos.

Could synthetic data be used to improve the performance of machine learning models used to detect rare species or infrequent events?"
80,"Deep learning solutions for joint species range estimation. These models jointly model thousands of species together. Current work has shown that joint modelling results in superior performance, when evaluated against ""expert"" range maps, compared to treating species independently. "
81,"Unintended consequences: It will become harder and harder to justify field time for early career researchers as projects capitalizing on the power of AI will be more productive. ECRs will put their time into learning AI skills rather than engaging with the messy reality of field work meaning fewer and fewer people in the field. This could have a range of consequences e.g.: 1) Careers in conservation science become less attractive (and less realistic-selection will be on AI skills not field skills) for certain types of people-we end up selecting into conservation only those attracted by this sort of work meaning insights which come from ‘field people’ are lost. 2) Fewer people in the field means fewer new insights which come from field observation.  3) People engage with people (not AI), fewer ecology/conservation researchers doing things in the field e.g. around important sites for biodiversity, may mean fewer opportunities to touch/inspire local people about the value of that habitat/species."
82,Improve horizon scanning activities
83,"Matching of conservation donors to action implementers will be greatly improved by establishment of an on-line facility that examines ideas and priorities on both sides of the partnership, and builds a performance profile of actors over time. Priorities of donors could be designed thematically, according to the topics they prefer, or according to the expected characteristics of implementes, e.g. first-time applicants, youth, women, experienced implementers, individuals, civil society organizations. The AI would also track the status of conservation priorities and actions, and help refine where investments would be more effective, as well as the type of implementer more likely to deliver optimal results. Such a service could be funded by subscription fees charged to donors and implementers, but scaled to the level of financial resources available to each."
84,"Models that predict protein structure are good at characterising structure in model species like rats, Drosophila etc.  How do we get AI to make predictions where those models fail because of lack of empirical data such as protein structures in species inhabiting extreme environments?"
85,"Population trend proxies from internet search frequencies can serve as 'early warning' and supplement existing wildlife population monitoring, for example for invertebrates (e.g. ticks, fleas, moths, aphids, ladybugs, flies, crane flies, earthworms and ants), for relationships between certain plants and pollinators (e.g. bumblebees/clover), and for zoonotic diseases (e.g. ticks/lymes borreliosis). See: 1) Jensen, P.M. et al. (2024). Environ. Monit. Assess. 196:276. https://link.springer.com/article/10.1007/s10661-024-12439-y; and 2) Jensen, P. M. et al. 2022. Insects 13(2), 176. https://doi.org/10.3390/insects13020176.
"
86,"Understand the sentiments of people towards conservation of species or places. Natural language processing methods can be used to assess sentiment e.g. (i) of visitors to protected and conservation areas to inform management and marketing, (ii) towards the conservation of species, including for the extinction of species; and (iii) of multiple stakeholders to conservation actions (e.g., trophy hunting and culling). "
87,"Use AI to foster a deeper appreciation and connection with nature.  Our increasingly urbanised and online world means that many young people are disconnected from nature. That disconnection is likely to mean that conservation is a low priority in their decision making.  Can AI help?  There are possibilities: AI can identify different plant and animal species, providing insights into the biodiversity around us, which might spark a desire to learn more about the natural world.  Such citizen-science data is starting to permeate conservation research, and sharing research findings could be inspiring if well-presented.  AI-generated virtual environments and simulations can provide immersive and interactive experiences of natural ecosystems, which could make nature more accessible and engaging, especially for those with limited opportunities to explore the outdoors. AI-powered augmented reality applications can overlay informative and educational content onto natural surroundings. But is fighting fire with fire really the solution to the disconnection problem?"
88,"With software makers keen to add pervasive AI features to their offerings, chipmakers have begun adding low-power AI co-processors to their hardware. Intel’s next generation ‘Lunar Lake’ mobile processors can perform 48 Trillion Operations Per Second (TOPS) in a 7W power footprint. These co-processors are primarily designed for tasks such as image enhancement during video conferencing, face and audio recognition, and locally running language models.

Could these capabilities be used to significantly expand the types of AI models being used in the field? This could cut the time between data collection and decision making significantly, as well as reducing the bandwidth required in the field. Models could instead initially produce summaries, potentially including only a few high priority features, which could be uploaded in even low-bandwidth environments.

Similar trends also exist in the embedded space, with numerous microcontrollers now featuring AI-tailored instruction sets or co-processors that enable low-power inference. A similar opportunity might apply here with monitoring devices able to summarise and prioritise captured data which is uploaded over low-bandwidth connections to larger field devices with larger power and bandwidth envelopes which are then able to do the same."
89,AI leveraged for predictive social network analysis - to understand changes in resource flow and organisation/network structure
90,"Geospatial biodiversity and ecosystem condition products such as the Biodiversity Intactness Index typically use EO-derived land cover or land use as a key model input, which means they essentially discard most data on the spatial and temporal characteristics of vegetation visible in satellite imagery. With the economies of scale of EOFM, we expect to see an abundance of new models that are able to estimate biodiversity loss or restoration directly from imagery, especially where we have extant training datasets such as PREDICTS, LPI, and others."
91,"Remote sensing data are widely used to map and monitor ecosystems, providing essential information for conservation decision making.  Building foundation models from remote sensing data will open up many new possibilities, because foundation models leverage large amounts of unlabelled data through self-supervised learning techniques. Key advantages include fusing multiple data modalities such as optical and radar imagery;  fine-tuning foundation models on smaller labelled datasets for various downstream tasks; global coverage that improve generalization across different geographic regions; enabling much smarter analyses of time-series dataset that are needed to track change.  In addition, remote sensing data often requires considerable “cleaning” before use,  e.g. because clouds obscure parts of the image or light conditions vary.  AI techniques could significantly enhance radiative transfer modelling in remote sensing enabling better generalisation for accurate canopy property retrievals."
92,"AI to accelerate and improve evidence synthesis in conservation
Evidence syntheses for biodiversity conservation are key for effective decision-making, yet are challenged by increasingly time-consuming tasks, a broad evidence base, and persistent underfunding. Large language models can accelerate evidence synthesis, and thus support efficient management of the biodiversity crisis, while making these exercises more timely, equitable and inclusive in terms of the evidence base considered.

Reference
Berger-Tal, O., et al. (2024). Leveraging AI to improve evidence synthesis in conservation. Trends in Ecology and Evolution. https://doi.org/10.1016/j.tree.2024.04.007
"
93,"Automated detection and reporting of cases of questionable research practices (such as p-hacking), potentially in conjunction with registered report."
94,"Enabling near real-time evidence synthesis. Conservation decisions are ideally based on the synthesis of the best available evidence.  Yet, most evidence syntheses done in the conservation space are static and fail to incorporate new evidence as it is generated (i.e., published).  AI has the potential be harnessed to identify relevant (new) evidence and integrate it into the existing evidence base and synthesize key messages.  Doing so will ensure decision makers have access to the best available evidence to guide them."
95,"Extraction of training data from literature. AI approaches are dependent on high quality training data, for biodiversity this typically means intensive field studies. Datasets such as PREDICTS aggregate results from past studies. Text mining approaches could be employed to automate harvesting static data from the literature. "
96,"Mobilized by the International Union for Conservation of Nature (IUCN), a new standard for species and ecosystem risk assessment will be created. Static publications such as the IUCN Red List of Threatened Species and the Red List of Ecosystems will be replaced by a real-time on-line service that will instantly display a document (similar to those published on red lists) with the status of species or ecosystem at spatial scales that span from municipalities to the entire planet, thus informing decision making at all relevant political scales. Other subdivisions of the world, such as watersheds, as well as custom-made polygons, that do not follow political borders, would also be allowed. Red List Categories and Criteria would be implemented using Artificial Intelligence and all data available from gray literature to peer reviewed publications, as well as on-line databases that spatially record the extend and dynamics of species and land cover in general. A small proportion of assessments (e.g. < 0.1%) would be randomly selected for verification and if corrections were necessary, flagged for teaching the AI. All assessments would be current all the time, and changes in the status of species and ecosystems could be detected instantly. A system of threatened species credits could be built in and used by individuals, civil society, corporations and governments to resource conservation interventions needed to maintain global biodiversity status above a predefined indicator value."
97,"Multilingual literature scanning. There are various distinct applications (e.g. species monitoring, ecosystem health monitoring, research tracking) that can benefit from recent NLP advances. These advances include Large Language Models (LLM) and their fine tuning on specified data corpora; topic models and topic specification; machine translation. Note that geographic regions important for conservation are often not English-language-speaking, and important information may be produced in local languages. Migrating species such as birds may have populations spanning many language usages. So it's desirable to take advantage of data across non-English sources, coupled with AI translation capabilities. The output of this could be a database (or databases) linking species, geo-locations, human activities etc that can be used to enrich or support specific conservation activities and analyses. "
98,Summarising evidence spatially and temporally: use LLMs to build structured data/taxanomies from any written evidence
99,"Using AI to support assessment of extinction risk to species by scanning the scientific literature and other materials on the internet to locate relevant information (on species population sizes, trends and distributions) in published and unpublished sources in all languages from online sources.
"
100,"Using Large language models to extract and interpret data and information from grey literature and reports on the internet. Grey literature is often sparsely available and is often hidden away on ‘obscure’ governmental or institutional databases. Also, old fashioned text matching can be difficult to use as a search tool for useful information For example, some reports may refer to national parks, some in other languages like ‘parque Nacional’, and some national parks just referred to by name, e.g. ‘Doñana’. All these reports are referring to national parks, but not in a consistent way. LLMs might be able to overcome this barrier. "
101,AI being able to detect bias in conservation databases (eg ‘in this global dataset you have a bias towards terrestrial species/this region etc etc’)
102,"Automated transects using Boston Dynamics robots, to automate the monitoring process and create a scalable biodiversity monitoring system "
103,"Museums hold huge numbers of specimens that could massively contribute to our knolwedge of diversity, especially for otherwise under recorded groups such as invertebrates. Robotic AI systems could work through trays of set insects, photographing each from various angles then ensuring have photographed the associated data. "
104,"Achieve a more equitable conservation.  This idea is not fully sussed out but I am thinking about how AI would provide opportunities to achieve conservation solutions that are more just and equitable by predicting outcomes to understand not just ecological consequences of decisions but how they will impact people (admitted, AI could also create unjust conditions!).  Interesting paper here:  https://link.springer.com/article/10.1007/s43681-020-00007-2"
